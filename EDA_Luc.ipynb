{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) of the NOAA Severe Weather Data Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to setup the notebook \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Maximum number of lines to display\n",
    "pd.options\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:08<00:00, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 180 non-empty dataframes in the list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'storm_data'\n",
    "\n",
    "# Load the data\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Read all the dfs into a list\n",
    "dfs = [df for df in (pd.read_csv(os.path.join(folder_path, file), low_memory=False) for file in tqdm(csv_files)) if not df.empty]\n",
    "print(f\"There are {len(dfs)} non-empty dataframes in the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected there are 3 sets of columns since there are the following different dataset types; details, locations and fatalities\n"
     ]
    }
   ],
   "source": [
    "columns_list = {tuple(df.columns) for df in dfs}\n",
    "print(f\"As expected there are {len(columns_list)} sets of columns since there are the following different dataset types; details, locations and fatalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (22, 11)\n"
     ]
    }
   ],
   "source": [
    "# Combine the dfs together by using 'episode_id' and 'event_id' as the key (as described in the pdf)\n",
    "combined_df = dfs[0]\n",
    "\n",
    "# Loop through the rest of the dfs and merge them with the combined_df, Event fatalities doesn't have episode_id\n",
    "for df in dfs[1:]:\n",
    "    if 'episode_id' in df.columns and 'episode_id' in combined_df.columns:\n",
    "        join_cols = ['episode_id', 'event_id']\n",
    "    elif 'event_id' in df.columns and 'event_id' in combined_df.columns:\n",
    "        join_cols = ['event_id']\n",
    "    else:\n",
    "        # No matching keys, skip\n",
    "        continue\n",
    "    combined_df = pd.merge(combined_df, df, on=join_cols, how='outer')\n",
    "\n",
    "print(\"Final shape:\", combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (3690781, 70)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the dfs together\n",
    "concat_df = pd.concat(dfs, axis=0)\n",
    "print(\"Final shape:\", concat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>FATALITY_TYPE</th>\n",
       "      <th>FATALITY_DATE</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "      <th>FATALITY_LOCATION</th>\n",
       "      <th>...</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>LOCATION_INDEX</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LAT2</th>\n",
       "      <th>LON2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195503.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1005348.0</td>\n",
       "      <td>10075750</td>\n",
       "      <td>D</td>\n",
       "      <td>03/16/1955 14:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195503.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1005349.0</td>\n",
       "      <td>10083328</td>\n",
       "      <td>D</td>\n",
       "      <td>03/01/1955 01:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195503.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1005350.0</td>\n",
       "      <td>10117464</td>\n",
       "      <td>D</td>\n",
       "      <td>03/13/1955 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195503.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1005351.0</td>\n",
       "      <td>10117756</td>\n",
       "      <td>D</td>\n",
       "      <td>03/22/1955 14:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195504.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1005352.0</td>\n",
       "      <td>9984179</td>\n",
       "      <td>D</td>\n",
       "      <td>04/21/1955 01:41:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FAT_YEARMONTH  FAT_DAY  FAT_TIME  FATALITY_ID  EVENT_ID FATALITY_TYPE  \\\n",
       "0       195503.0     16.0    1430.0    1005348.0  10075750             D   \n",
       "1       195503.0      1.0     152.0    1005349.0  10083328             D   \n",
       "2       195503.0     13.0    2100.0    1005350.0  10117464             D   \n",
       "3       195503.0     22.0    1430.0    1005351.0  10117756             D   \n",
       "4       195504.0     21.0     141.0    1005352.0   9984179             D   \n",
       "\n",
       "         FATALITY_DATE  FATALITY_AGE FATALITY_SEX FATALITY_LOCATION  ...  \\\n",
       "0  03/16/1955 14:30:00           NaN          NaN               NaN  ...   \n",
       "1  03/01/1955 01:52:00           NaN          NaN               NaN  ...   \n",
       "2  03/13/1955 21:00:00           NaN          NaN               NaN  ...   \n",
       "3  03/22/1955 14:30:00           NaN          NaN               NaN  ...   \n",
       "4  04/21/1955 01:41:00           NaN          NaN               NaN  ...   \n",
       "\n",
       "   DATA_SOURCE  YEARMONTH  LOCATION_INDEX  RANGE  AZIMUTH  LOCATION  LATITUDE  \\\n",
       "0          NaN        NaN             NaN    NaN      NaN       NaN       NaN   \n",
       "1          NaN        NaN             NaN    NaN      NaN       NaN       NaN   \n",
       "2          NaN        NaN             NaN    NaN      NaN       NaN       NaN   \n",
       "3          NaN        NaN             NaN    NaN      NaN       NaN       NaN   \n",
       "4          NaN        NaN             NaN    NaN      NaN       NaN       NaN   \n",
       "\n",
       "   LONGITUDE LAT2  LON2  \n",
       "0        NaN  NaN   NaN  \n",
       "1        NaN  NaN   NaN  \n",
       "2        NaN  NaN   NaN  \n",
       "3        NaN  NaN   NaN  \n",
       "4        NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FAT_YEARMONTH', 'FAT_DAY', 'FAT_TIME', 'FATALITY_ID', 'EVENT_ID',\n",
       "       'FATALITY_TYPE', 'FATALITY_DATE', 'FATALITY_AGE', 'FATALITY_SEX',\n",
       "       'FATALITY_LOCATION', 'EVENT_YEARMONTH', 'BEGIN_YEARMONTH', 'BEGIN_DAY',\n",
       "       'BEGIN_TIME', 'END_YEARMONTH', 'END_DAY', 'END_TIME', 'EPISODE_ID',\n",
       "       'STATE', 'STATE_FIPS', 'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE',\n",
       "       'CZ_FIPS', 'CZ_NAME', 'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE',\n",
       "       'END_DATE_TIME', 'INJURIES_DIRECT', 'INJURIES_INDIRECT',\n",
       "       'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS',\n",
       "       'SOURCE', 'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY',\n",
       "       'TOR_F_SCALE', 'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO',\n",
       "       'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME',\n",
       "       'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE',\n",
       "       'END_AZIMUTH', 'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT',\n",
       "       'END_LON', 'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE',\n",
       "       'YEARMONTH', 'LOCATION_INDEX', 'RANGE', 'AZIMUTH', 'LOCATION',\n",
       "       'LATITUDE', 'LONGITUDE', 'LAT2', 'LON2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'EVENT_ID' in concat_df.columns and 'EPISODE_ID' in concat_df.columns, \"The columns 'EVENT_ID' and 'EPISODE_ID' are not in the dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>FATALITY_TYPE</th>\n",
       "      <th>FATALITY_DATE</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "      <th>FATALITY_LOCATION</th>\n",
       "      <th>EVENT_YEARMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195807</td>\n",
       "      <td>1</td>\n",
       "      <td>1510</td>\n",
       "      <td>1005456</td>\n",
       "      <td>10055208</td>\n",
       "      <td>D</td>\n",
       "      <td>07/01/1958 15:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195808</td>\n",
       "      <td>4</td>\n",
       "      <td>1930</td>\n",
       "      <td>1005457</td>\n",
       "      <td>10055429</td>\n",
       "      <td>D</td>\n",
       "      <td>08/04/1958 19:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195809</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "      <td>1005458</td>\n",
       "      <td>10040343</td>\n",
       "      <td>D</td>\n",
       "      <td>09/07/1958 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195810</td>\n",
       "      <td>19</td>\n",
       "      <td>735</td>\n",
       "      <td>1005459</td>\n",
       "      <td>9984944</td>\n",
       "      <td>D</td>\n",
       "      <td>10/19/1958 07:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195810</td>\n",
       "      <td>10</td>\n",
       "      <td>1905</td>\n",
       "      <td>1005460</td>\n",
       "      <td>10048193</td>\n",
       "      <td>D</td>\n",
       "      <td>10/10/1958 19:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FAT_YEARMONTH  FAT_DAY  FAT_TIME  FATALITY_ID  EVENT_ID FATALITY_TYPE  \\\n",
       "0         195807        1      1510      1005456  10055208             D   \n",
       "1         195808        4      1930      1005457  10055429             D   \n",
       "2         195809        7      1600      1005458  10040343             D   \n",
       "3         195810       19       735      1005459   9984944             D   \n",
       "4         195810       10      1905      1005460  10048193             D   \n",
       "\n",
       "         FATALITY_DATE  FATALITY_AGE  FATALITY_SEX  FATALITY_LOCATION  \\\n",
       "0  07/01/1958 15:10:00           NaN           NaN                NaN   \n",
       "1  08/04/1958 19:30:00           NaN           NaN                NaN   \n",
       "2  09/07/1958 16:00:00           NaN           NaN                NaN   \n",
       "3  10/19/1958 07:35:00           NaN           NaN                NaN   \n",
       "4  10/10/1958 19:05:00           NaN           NaN                NaN   \n",
       "\n",
       "   EVENT_YEARMONTH  \n",
       "0           195807  \n",
       "1           195808  \n",
       "2           195809  \n",
       "3           195810  \n",
       "4           195810  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out a random dataframe\n",
    "dfs[50].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
